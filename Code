import pandas as pd
from pandas import Series, DataFrame
import pandas.io.data as web
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
import numpy as np
from math import log, e
from scipy.stats import norm 

# here we delete the columns we dont need. We set that index to dates and parse dates
#options = pd.read_excel('Options_Test.xlsx', 'Hoja1', index_col='Date[L]', parse_date=True)
options = pd.read_excel('Options_Test.xlsx', 'Hoja1', parse_date=True)
#del options['EX']
del options['Open Interest']
del options['Settle']
#del options['Data']
#del options['Source']
del options['Time[L]']
del options['Type']
del options['Qualifiers']
options['Days_to_Exp'] = (options.Exp_Date - options.Date)
options.head()


#We need to drop the NaN to make sure we get the rows that contain important data. Since all the data from reuters comes w/
#all 24 hours of data. Or in case of EOD it has 7 days.

options = options.dropna()
options = options.sort('Date')
options

#S_0 = underlying price (USD per share)
#X = strike price (USD per share)
#v = volatility (% p.a.)
#r = continuously compounded risk-free interest rate (% p.a.)
#div = continuously compounded dividend yield (% p.a.)
#N = where N(x) is the standard normal cumulative distribution function.
#t = time to expiration (% of year)

x = 266 # number of days to exp.
r = 0.05
v = 0.39
div = 0.0
t = x/365.0
S_0 = 107.87
X = 105.0
T = 365.0 #Total days in a year

d1 = (log(S_0/X) + t * (r - div + (v**2)/2)) / (v * sqrt(t)) #CORRECT
d2 = (d1 - v * sqrt(t)) #CORRECT
call_delta = e**(-div*t) * norm.cdf(d1)  #CORRECT
Gamma = (e**(-div*t)) / (S_0 * v * sqrt(t)) * (1/(sqrt(2*pi))) * e**((-(d1)**2)/2) #CORRECT
